{"cells":[{"cell_type":"markdown","metadata":{},"source":["## The title is a bit clickbait, because in the inference I've used regex for emails and numbers, so the LB score for this model would be about .955-.956 without them.\n","\n","- The only thing I did was setting truncation to false in the tokenizer. That's it."]},{"cell_type":"markdown","metadata":{},"source":["## üõë Wait a second - after this you should also look at the inference notebook\n","- My inference notebook (containing equally many emojis) is here:\n","- https://www.kaggle.com/code/valentinwerner/893-deberta3base-inference"]},{"cell_type":"markdown","metadata":{},"source":["## üèüÔ∏è Credits (because this baseline did mostly already exist when I joiend)\n","\n","- @Nicholas Broad published the transformer baseline which performs only marginally worse: https://www.kaggle.com/code/nbroad/transformer-ner-baseline-lb-0-854\n","- @Joseph Josia published the training notebook which I basically copy pasted (which is based itself on nbroad, but yeah): https://www.kaggle.com/code/takanashihumbert/piidd-deberta-model-starter-training\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## üí° What I added\n","- Downsampling negative samples (samples without labels, but they possible still work as examples where names should not be tagged as name)\n","- Adding @moths external data: https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/469493\n","- Adding PJMathematicianss external data: https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/470921\n","- However, I used my cleaned version instead (the punctuation is flawed in the original data set at the time of this trainign): https://www.kaggle.com/code/valentinwerner/fix-punctuation-tokenization-external-dataset\n","\n","Doing this brought the LB score to .888 - Trained in Kaggle Notebook, no tricks or secrets.\n","\n","- I added emojis because that seems to be the kaggle upvote meta"]},{"cell_type":"markdown","metadata":{},"source":["## üìù Config & Imports\n","- 1024 max length has been working well for me. As some samples are longer, you may want to go as high as you can "]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-16T15:08:18.021740Z","iopub.status.busy":"2024-03-16T15:08:18.020803Z","iopub.status.idle":"2024-03-16T15:08:18.045551Z","shell.execute_reply":"2024-03-16T15:08:18.044579Z","shell.execute_reply.started":"2024-03-16T15:08:18.021706Z"},"trusted":true},"outputs":[],"source":["from dotenv import load_dotenv\n","import os\n","\n","load_dotenv(\"/kaggle/.env\")\n","WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n","\n","TRAINING_MODEL_PATH = \"microsoft/deberta-v3-large\"\n","TRAINING_MAX_LENGTH = 1536\n","STRIDE = 128\n","OUTPUT_DIR = \"/kaggle/output/deberta3large_lstm\"\n","\n","BATCH_SIZE = 1\n","ACC_STEPS = 2\n","EPOCHS = 4\n","LR = 2e-5\n","\n","arch_suffix = \"deberta_large_LSTM\"\n","\n","name = f\"ex_ec2_{arch_suffix}_return_overflowing_tokens\""]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:08:35.856151Z","iopub.status.busy":"2024-03-16T15:08:35.855839Z","iopub.status.idle":"2024-03-16T15:08:56.055800Z","shell.execute_reply":"2024-03-16T15:08:56.054787Z","shell.execute_reply.started":"2024-03-16T15:08:35.856125Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import json\n","import argparse\n","from itertools import chain\n","from functools import partial\n","from typing import Optional, Tuple, Union\n","\n","import torch\n","from torch import nn\n","from transformers import (\n","    AutoTokenizer, \n","    Trainer, \n","    TrainingArguments,\n","    AutoModelForTokenClassification, \n","    DataCollatorForTokenClassification, \n","    DebertaV2ForTokenClassification\n",")\n","from transformers.models.deberta_v2 import DebertaV2PreTrainedModel, DebertaV2Model\n","from transformers.models.deberta_v2.modeling_deberta_v2 import (\n","    DEBERTA_START_DOCSTRING,\n","    DEBERTA_INPUTS_DOCSTRING,\n","    _CHECKPOINT_FOR_DOC,\n","    _CONFIG_FOR_DOC\n",")\n","from transformers.utils import(\n","    add_code_sample_docstrings,\n","    add_start_docstrings,\n","    add_start_docstrings_to_model_forward,\n",")\n","from transformers.modeling_outputs import TokenClassifierOutput, TokenClassifierOutput\n","import evaluate\n","from datasets import Dataset, features\n","import numpy as np\n","\n","import wandb"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:08:56.059162Z","iopub.status.busy":"2024-03-16T15:08:56.058457Z","iopub.status.idle":"2024-03-16T15:08:58.583742Z","shell.execute_reply":"2024-03-16T15:08:58.582790Z","shell.execute_reply.started":"2024-03-16T15:08:56.059124Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msueyoshi124\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:08:58.585644Z","iopub.status.busy":"2024-03-16T15:08:58.584980Z","iopub.status.idle":"2024-03-16T15:09:29.433085Z","shell.execute_reply":"2024-03-16T15:09:29.431691Z","shell.execute_reply.started":"2024-03-16T15:08:58.585618Z"},"trusted":true},"outputs":[{"data":{"text/html":["wandb version 0.16.4 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/notebook/wandb/run-20240317_070932-8tijrg7e</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/sueyoshi124/kaggle_pii/runs/8tijrg7e' target=\"_blank\">ex_ec2_deberta_large_LSTM_return_overflowing_tokens</a></strong> to <a href='https://wandb.ai/sueyoshi124/kaggle_pii' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/sueyoshi124/kaggle_pii' target=\"_blank\">https://wandb.ai/sueyoshi124/kaggle_pii</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/sueyoshi124/kaggle_pii/runs/8tijrg7e' target=\"_blank\">https://wandb.ai/sueyoshi124/kaggle_pii/runs/8tijrg7e</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["run = wandb.init(\n","    project=\"kaggle_pii\",\n","    name=name,\n","    config={\n","        \"learning_rate\": LR,\n","        \"architecture\":  f\"{TRAINING_MODEL_PATH}_{arch_suffix}\",\n","        \"epochs\": EPOCHS,\n","        \"batch_size\": BATCH_SIZE,\n","        \"gradient_accumulation_steps\": ACC_STEPS,\n","        \"train_max_length\": TRAINING_MAX_LENGTH,\n","    }\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## üó∫Ô∏è Data Selection and Label Mapping\n","- As mentioned before, I additionaly use the moth dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:29.434909Z","iopub.status.busy":"2024-03-16T15:09:29.434578Z","iopub.status.idle":"2024-03-16T15:09:33.859073Z","shell.execute_reply":"2024-03-16T15:09:33.858075Z","shell.execute_reply.started":"2024-03-16T15:09:29.434878Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["original datapoints:  6807\n","external datapoints:  4434\n","moredata datapoints:  2000\n","combined:  9333\n"]}],"source":["data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n","\n","# downsampling of negative examples\n","p=[] # positive samples (contain relevant labels)\n","n=[] # negative samples (presumably contain entities that are possibly wrongly classified as entity)\n","for d in data:\n","    if any(np.array(d[\"labels\"]) != \"O\"): p.append(d)\n","    else: n.append(d)\n","print(\"original datapoints: \", len(data))\n","\n","external = json.load(open(\"/kaggle/input/fix-punctuation-tokenization-external-dataset/pii_dataset_fixed.json\"))\n","print(\"external datapoints: \", len(external))\n","\n","moredata = json.load(open(\"/kaggle/input/fix-punctuation-tokenization-external-dataset/moredata_dataset_fixed.json\"))\n","print(\"moredata datapoints: \", len(moredata))\n","\n","data = moredata+external+p+n[:len(n)//3]\n","print(\"combined: \", len(data))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:33.860598Z","iopub.status.busy":"2024-03-16T15:09:33.860299Z","iopub.status.idle":"2024-03-16T15:09:33.942920Z","shell.execute_reply":"2024-03-16T15:09:33.942038Z","shell.execute_reply.started":"2024-03-16T15:09:33.860573Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 'B-EMAIL', 1: 'B-ID_NUM', 2: 'B-NAME_STUDENT', 3: 'B-PHONE_NUM', 4: 'B-STREET_ADDRESS', 5: 'B-URL_PERSONAL', 6: 'B-USERNAME', 7: 'I-ID_NUM', 8: 'I-NAME_STUDENT', 9: 'I-PHONE_NUM', 10: 'I-STREET_ADDRESS', 11: 'I-URL_PERSONAL', 12: 'O'}\n"]}],"source":["all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","label2id = {l: i for i,l in enumerate(all_labels)}\n","id2label = {v:k for k,v in label2id.items()}\n","\n","target = [\n","    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n","    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n","    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n","]\n","\n","print(id2label)"]},{"cell_type":"markdown","metadata":{},"source":["## ‚ôüÔ∏è Data Tokenization\n","- This tokenizer is actually special, comparing to usual NLP challenges"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:33.944385Z","iopub.status.busy":"2024-03-16T15:09:33.944112Z","iopub.status.idle":"2024-03-16T15:09:33.965388Z","shell.execute_reply":"2024-03-16T15:09:33.964453Z","shell.execute_reply.started":"2024-03-16T15:09:33.944361Z"},"trusted":true},"outputs":[],"source":["def tokenize_train(example, tokenizer, label2id):\n","\n","    # rebuild text from tokens\n","    text = []\n","    labels = []\n","    \n","    idx = 0\n","\n","    for t, l, ws in zip(\n","        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n","    ):\n","        text.append(t)\n","        labels.extend([l] * len(t))\n","\n","        if ws:\n","            text.append(\" \")\n","            labels.append(\"O\")\n","            \n","\n","    # actual tokenization\n","    tokenized = tokenizer(\n","        \"\".join(text),\n","        return_offsets_mapping=True,\n","        max_length=TRAINING_MAX_LENGTH, \n","        stride=STRIDE,\n","        truncation=True, \n","        return_overflowing_tokens=True,\n","    )\n","\n","    labels = np.array(labels)\n","\n","    text = \"\".join(text)\n","    token_labels = []\n","    \n","    for offsets in tokenized.offset_mapping:\n","        tmp_labels = []\n","        \n","        for idxs in offsets:        \n","            start_idx = idxs[0]\n","            end_idx = idxs[1]\n","            # CLS token\n","            if start_idx == 0 and end_idx == 0:\n","                tmp_labels.append(-100)\n","                continue\n","\n","            # case when token starts with whitespace\n","            if text[start_idx].isspace():\n","                start_idx += 1\n","\n","            tmp_labels.append(label2id[labels[start_idx]])\n","        token_labels.append(tmp_labels)\n","    \n","#     length = len(tokenized.input_ids)\n","\n","    tokenized.pop(\"overflow_to_sample_mapping\")\n","    tokenized.pop(\"offset_mapping\")\n","    return {\n","        **tokenized, \n","        \"labels\": token_labels, \n","#         \"length\": length,\n","#         \"token_map\": token_map,\n","    }"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:33.968812Z","iopub.status.busy":"2024-03-16T15:09:33.968400Z","iopub.status.idle":"2024-03-16T15:09:36.596328Z","shell.execute_reply":"2024-03-16T15:09:36.595109Z","shell.execute_reply.started":"2024-03-16T15:09:33.968777Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:36.598748Z","iopub.status.busy":"2024-03-16T15:09:36.597788Z","iopub.status.idle":"2024-03-16T15:09:38.447530Z","shell.execute_reply":"2024-03-16T15:09:38.446401Z","shell.execute_reply.started":"2024-03-16T15:09:36.598714Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19e6bec83fa6453d8eca46dcecba0729","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/9333 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["n = 64\n","ds = Dataset.from_dict({\n","    \"full_text\": [x[\"full_text\"] for x in data],\n","    \"document\": [str(x[\"document\"]) for x in data],\n","    \"tokens\": [x[\"tokens\"] for x in data],\n","    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n","    \"provided_labels\": [x[\"labels\"] for x in data],\n","})\n","# ds = Dataset.from_dict({\n","#     \"full_text\": [x[\"full_text\"] for x in data[:n]],\n","#     \"document\": [str(x[\"document\"]) for x in data[:n]],\n","#     \"tokens\": [x[\"tokens\"] for x in data[:n]],\n","#     \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data[:n]],\n","#     \"provided_labels\": [x[\"labels\"] for x in data[:n]],\n","# })\n","ds = ds.map(\n","    tokenize_train, \n","    fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id}, \n","    remove_columns=ds.column_names,\n","    num_proc=4\n",")\n","# ds = ds.class_encode_column(\"group\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:38.449290Z","iopub.status.busy":"2024-03-16T15:09:38.448934Z","iopub.status.idle":"2024-03-16T15:09:38.650465Z","shell.execute_reply":"2024-03-16T15:09:38.649517Z","shell.execute_reply.started":"2024-03-16T15:09:38.449261Z"},"trusted":true},"outputs":[],"source":["train_dict = None\n","for d in ds:\n","    if train_dict is None:\n","        train_dict = d\n","    else:\n","        for k, v in d.items():\n","            train_dict[k] += d[k]\n","\n","ds = Dataset.from_dict(train_dict)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:38.652349Z","iopub.status.busy":"2024-03-16T15:09:38.651879Z","iopub.status.idle":"2024-03-16T15:09:38.658563Z","shell.execute_reply":"2024-03-16T15:09:38.657514Z","shell.execute_reply.started":"2024-03-16T15:09:38.652314Z"},"trusted":true},"outputs":[],"source":["# x = ds[0]\n","\n","# for t,l in zip(x[\"tokens\"], x[\"provided_labels\"]):\n","#     if l != \"O\":\n","#         print((t,l))\n","\n","# print(\"*\"*100)\n","\n","# for t, l in zip(tokenizer.convert_ids_to_tokens(x[\"input_ids\"]), x[\"labels\"]):\n","#     if id2label[l] != \"O\":\n","#         print((t,id2label[l]))"]},{"cell_type":"markdown","metadata":{},"source":["## üßÆ Competition metrics\n","- Note that we are not using the normal F1 score.\n","- Although it is early in the competition, there are plenty of discsussions already explaining this:\n","- e.g., here: https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/470024"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:38.660294Z","iopub.status.busy":"2024-03-16T15:09:38.659945Z","iopub.status.idle":"2024-03-16T15:09:38.675235Z","shell.execute_reply":"2024-03-16T15:09:38.674302Z","shell.execute_reply.started":"2024-03-16T15:09:38.660264Z"},"trusted":true},"outputs":[],"source":["from seqeval.metrics import recall_score, precision_score\n","from seqeval.metrics import classification_report\n","from seqeval.metrics import f1_score\n","\n","def compute_metrics(p, all_labels):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    \n","    recall = recall_score(true_labels, true_predictions)\n","    precision = precision_score(true_labels, true_predictions)\n","    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n","    \n","    results = {\n","        'recall': recall,\n","        'precision': precision,\n","        'f1': f1_score\n","    }\n","    return results"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:38.676741Z","iopub.status.busy":"2024-03-16T15:09:38.676450Z","iopub.status.idle":"2024-03-16T15:09:38.693961Z","shell.execute_reply":"2024-03-16T15:09:38.692914Z","shell.execute_reply.started":"2024-03-16T15:09:38.676719Z"},"trusted":true},"outputs":[],"source":["@add_start_docstrings(\n","    \"\"\"\n","    DeBERTa Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for\n","    Named-Entity-Recognition (NER) tasks.\n","    \"\"\",\n","    DEBERTA_START_DOCSTRING,\n",")\n","class DebertaV2LstmForTokenClassification(DebertaV2PreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.deberta = DebertaV2Model(config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size * 2, config.num_labels)\n","        \n","        self.lstm =  nn.LSTM(\n","            config.hidden_size, \n","            config.hidden_size, \n","            num_layers=1,\n","            batch_first=True, \n","            bidirectional=True\n","        )\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","        \n","        # Initialize weights and apply final processing\n","        self.post_init()\n","    \n","    @add_start_docstrings_to_model_forward(DEBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n","    @add_code_sample_docstrings(\n","        checkpoint=_CHECKPOINT_FOR_DOC,\n","        output_type=TokenClassifierOutput,\n","        config_class=_CONFIG_FOR_DOC,\n","    )\n","    def forward(\n","        self,\n","        input_ids: Optional[torch.Tensor] = None,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        token_type_ids: Optional[torch.Tensor] = None,\n","        position_ids: Optional[torch.Tensor] = None,\n","        inputs_embeds: Optional[torch.Tensor] = None,\n","        labels: Optional[torch.Tensor] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","    ) -> Union[Tuple, TokenClassifierOutput]:\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n","            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.deberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        \n","        sequence_output, _ = self.lstm(outputs[0])\n","        sequence_output = self.dropout(sequence_output)\n","        \n","        logits1 = self.classifier(self.dropout1(sequence_output))\n","        logits2 = self.classifier(self.dropout2(sequence_output))\n","        logits3 = self.classifier(self.dropout3(sequence_output))\n","        logits4 = self.classifier(self.dropout4(sequence_output))\n","        logits5 = self.classifier(self.dropout5(sequence_output))\n","\n","        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","\n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[1:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return TokenClassifierOutput(\n","            loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions\n","        )"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:38.696062Z","iopub.status.busy":"2024-03-16T15:09:38.695704Z","iopub.status.idle":"2024-03-16T15:09:41.391116Z","shell.execute_reply":"2024-03-16T15:09:41.390202Z","shell.execute_reply.started":"2024-03-16T15:09:38.696031Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DebertaV2LstmForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'lstm.bias_hh_l0_reverse', 'lstm.weight_ih_l0_reverse', 'lstm.weight_ih_l0', 'lstm.bias_ih_l0_reverse', 'lstm.weight_hh_l0', 'classifier.weight', 'lstm.weight_hh_l0_reverse', 'lstm.bias_hh_l0', 'lstm.bias_ih_l0']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = DebertaV2LstmForTokenClassification.from_pretrained(\n","    TRAINING_MODEL_PATH,\n","    num_labels=len(all_labels),\n","    id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes=True\n",")\n","collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:41.392624Z","iopub.status.busy":"2024-03-16T15:09:41.392347Z","iopub.status.idle":"2024-03-16T15:09:41.397237Z","shell.execute_reply":"2024-03-16T15:09:41.396192Z","shell.execute_reply.started":"2024-03-16T15:09:41.392603Z"},"trusted":true},"outputs":[],"source":["# I decided to uses no eval\n","# final_ds = ds.train_test_split(test_size=0.2, seed=42) # cannot use stratify_by_column='group'\n","# final_ds"]},{"cell_type":"markdown","metadata":{},"source":["## üèãüèª‚Äç‚ôÄÔ∏è Training\n","- I actually do not use an eval set for submission to train on all data\n","- Values are not really tuned and go by gut feeling, as this is my first iteration / baseline"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:41.399181Z","iopub.status.busy":"2024-03-16T15:09:41.398841Z","iopub.status.idle":"2024-03-16T15:09:41.965415Z","shell.execute_reply":"2024-03-16T15:09:41.964397Z","shell.execute_reply.started":"2024-03-16T15:09:41.399150Z"},"trusted":true},"outputs":[],"source":["# I actually chose to not use any validation set. This is only for the model I use for submission.\n","args = TrainingArguments(\n","    output_dir=OUTPUT_DIR, \n","    fp16=True,\n","    learning_rate=LR,\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    gradient_accumulation_steps=ACC_STEPS,\n","    report_to=\"wandb\",\n","    evaluation_strategy=\"no\",\n","    do_eval=False,\n","    logging_steps=20,\n","    lr_scheduler_type='cosine',\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    warmup_ratio=0.1,\n","    weight_decay=0.01,\n","    save_strategy=\"epoch\"\n",")\n","\n","trainer = Trainer(\n","    model=model, \n","    args=args, \n","    train_dataset=ds,\n","    data_collator=collator, \n","    tokenizer=tokenizer,\n","    compute_metrics=partial(compute_metrics, all_labels=all_labels),\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:09:41.968044Z","iopub.status.busy":"2024-03-16T15:09:41.967683Z","iopub.status.idle":"2024-03-16T15:10:46.054207Z","shell.execute_reply":"2024-03-16T15:10:46.053193Z","shell.execute_reply.started":"2024-03-16T15:09:41.967989Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='699' max='18768' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  699/18768 05:45 < 2:29:26, 2.02 it/s, Epoch 0.15/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>20</td>\n","      <td>2.451400</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.412400</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.254300</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.994300</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.626200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.139900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.650200</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.356600</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.206800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.195400</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.187900</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.179400</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.120700</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.141400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.111500</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.077800</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.075200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.086400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.090500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.057100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.058600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.038900</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.038300</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.039100</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.032200</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.031700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.026500</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.020300</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.020900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%time\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["## üíæ Save models\n","- You can click on \"Save version\" (top right) and \"Save & Run All (Commit)\"\n","- Then you can use this notebook as input for your inference notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:10:46.055832Z","iopub.status.busy":"2024-03-16T15:10:46.055535Z","iopub.status.idle":"2024-03-16T15:10:47.853445Z","shell.execute_reply":"2024-03-16T15:10:47.852320Z","shell.execute_reply.started":"2024-03-16T15:10:46.055808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd13e1c2170>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd0ff0e69e0, raw_cell=\"# trainer.save_model(\"deberta3base_1024\")\n","# tokeni..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d795f6b6167676c655f646f636b65722d6170702d31227d@ssh-remote%2Bec2-44-192-34-117.compute-1.amazonaws.com/kaggle/notebook/deberta3large-lstm-training.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"]},{"ename":"TypeError","evalue":"_WandbInit._resume_backend() takes 1 positional argument but 2 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"]},{"name":"stdout","output_type":"stream","text":["Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd13e1c2170>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd0ff0e6770, execution_count=20 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd0ff0e69e0, raw_cell=\"# trainer.save_model(\"deberta3base_1024\")\n","# tokeni..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d795f6b6167676c655f646f636b65722d6170702d31227d@ssh-remote%2Bec2-44-192-34-117.compute-1.amazonaws.com/kaggle/notebook/deberta3large-lstm-training.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"]},{"ename":"TypeError","evalue":"_WandbInit._pause_backend() takes 1 positional argument but 2 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"]}],"source":["# trainer.save_model(\"deberta3base_1024\")\n","# tokenizer.save_pretrained(\"deberta3base_1024\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd13e1c2170>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd13eaf4130, raw_cell=\"torch.save(model.state_dict(), os.path.join(OUTPUT..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d795f6b6167676c655f646f636b65722d6170702d31227d@ssh-remote%2Bec2-44-192-34-117.compute-1.amazonaws.com/kaggle/notebook/deberta3large-lstm-training.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"]},{"ename":"TypeError","evalue":"_WandbInit._resume_backend() takes 1 positional argument but 2 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"]},{"name":"stdout","output_type":"stream","text":["Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd13e1c2170>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd0ff0e49d0, execution_count=21 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd13eaf4130, raw_cell=\"torch.save(model.state_dict(), os.path.join(OUTPUT..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d795f6b6167676c655f646f636b65722d6170702d31227d@ssh-remote%2Bec2-44-192-34-117.compute-1.amazonaws.com/kaggle/notebook/deberta3large-lstm-training.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"]},{"ename":"TypeError","evalue":"_WandbInit._pause_backend() takes 1 positional argument but 2 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"]}],"source":["torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"pt_output.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T15:10:47.855171Z","iopub.status.busy":"2024-03-16T15:10:47.854802Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd13e1c2170>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd0ff0e4e20, raw_cell=\"wandb.finish()\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6d795f6b6167676c655f646f636b65722d6170702d31227d@ssh-remote%2Bec2-44-192-34-117.compute-1.amazonaws.com/kaggle/notebook/deberta3large-lstm-training.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"]},{"ename":"TypeError","evalue":"_WandbInit._resume_backend() takes 1 positional argument but 2 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 33473... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"Exception","evalue":"The wandb backend process has shutdown","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1788\u001b[0m, in \u001b[0;36mRun._atexit_cleanup\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1788\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ki:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1963\u001b[0m, in \u001b[0;36mRun._on_finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface:\n\u001b[0;32m-> 1963\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_telemetry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_telemetry_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;66;03m# TODO: we need to handle catastrophic failure better\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;66;03m# some tests were timing out on sending exit for reasons not clear to me\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:67\u001b[0m, in \u001b[0;36mInterfaceShared._publish_telemetry\u001b[0;34m(self, telem)\u001b[0m\n\u001b[1;32m     66\u001b[0m rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_record(telemetry\u001b[38;5;241m=\u001b[39mtelem)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_queue.py:45\u001b[0m, in \u001b[0;36mInterfaceQueue._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_check \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe wandb backend process has shutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local:\n","\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2848\u001b[0m, in \u001b[0;36mfinish\u001b[0;34m(exit_code, quiet)\u001b[0m\n\u001b[1;32m   2838\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Marks a run as finished, and finishes uploading all data.\u001b[39;00m\n\u001b[1;32m   2839\u001b[0m \n\u001b[1;32m   2840\u001b[0m \u001b[38;5;124;03mThis is used when creating multiple runs in the same process.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;124;03m    quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mrun:\n\u001b[0;32m-> 2848\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1463\u001b[0m, in \u001b[0;36mRun.finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m TeardownStage\u001b[38;5;241m.\u001b[39mEARLY:\n\u001b[1;32m   1461\u001b[0m         hook\u001b[38;5;241m.\u001b[39mcall()\n\u001b[0;32m-> 1463\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_atexit_cleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl\u001b[38;5;241m.\u001b[39m_global_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl\u001b[38;5;241m.\u001b[39m_global_run_stack\u001b[38;5;241m.\u001b[39mpop()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1797\u001b[0m, in \u001b[0;36mRun._atexit_cleanup\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_console_stop()\n\u001b[0;32m-> 1797\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1798\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem finishing run\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   1799\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mtermerror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem finishing run\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/backend/backend.py:245\u001b[0m, in \u001b[0;36mBackend.cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb_process:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb_process\u001b[38;5;241m.\u001b[39mjoin()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:458\u001b[0m, in \u001b[0;36mInterfaceShared.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_router:\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_router\u001b[38;5;241m.\u001b[39mjoin()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:599\u001b[0m, in \u001b[0;36mInterfaceBase.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop:\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 599\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate_shutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:455\u001b[0m, in \u001b[0;36mInterfaceShared._communicate_shutdown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m request \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mRequest(shutdown\u001b[38;5;241m=\u001b[39mpb\u001b[38;5;241m.\u001b[39mShutdownRequest())\n\u001b[1;32m    454\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_record(request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 455\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:213\u001b[0m, in \u001b[0;36mInterfaceShared._communicate\u001b[0;34m(self, rec, timeout, local)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_communicate\u001b[39m(\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m, rec: pb\u001b[38;5;241m.\u001b[39mRecord, timeout: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, local: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    212\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[pb\u001b[38;5;241m.\u001b[39mResult]:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:218\u001b[0m, in \u001b[0;36mInterfaceShared._communicate_async\u001b[0;34m(self, rec, local)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_router\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_check \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe wandb backend process has shutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    219\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_router\u001b[38;5;241m.\u001b[39msend_and_receive(rec, local\u001b[38;5;241m=\u001b[39mlocal)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m future\n","\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"]}],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!aws ec2 stop-instances --instance-ids i-0449cb0b94ddaa813"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7500999,"sourceId":66653,"sourceType":"competition"},{"datasetId":4492162,"sourceId":7696551,"sourceType":"datasetVersion"},{"sourceId":163088908,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
