dataset: 
    json_filepath: /kaggle/input/pii-detection-removal-from-educational-data/train.json
    extra_filepath:
    - /kaggle/input/pii-mixtral8x7b-generated-essays/mpware_mixtral8x7b_v1.1-no-i-username.json
    negative_ratio: 0.3
fold:
    num_folds: 4
    fold: 3
model_class: DebertaV2ForTokenClassification
architecture:
    backbone: microsoft/deberta-v3-large
    name: ec2_deberta_large_bf16_0966
    freeze_layers: 6
    freeze_embedding: False
environment:
    mixed_precision: true
    seed: 42
tokenizer:
    max_length: 1800
    stride: 128
training:
    batch_size: 1
    eval_batch_size: 1
    epochs: 3
    grad_accumulation: 16
    learning_rate: 2.5e-5
    schedule: linear 
    evaluation_strategy: steps
    eval_steps: 50
    metric_for_best_model: f5
    warmup_ratio: 0.1
    weight_decay: 0.01
    bf16: True
    fp16: False
    adv_param: 'weight'
    adv_lr: 0.0001
    adv_eps: 0.0001
    awp_start: 1
output:
    suffix: /kaggle/output/deberta3large
debug: False